intervalo = c(estimativa[2] - 1.96*estimativa[4],
estimativa[2] + 1.96*estimativa[4])
print(intervalo[1])
print(intervalo[2])
if(2 >= intervalo[1] && 2 <= intervalo[2]){
cat("Dentro")
}
library(MatchIt)
library(lmtest)
library(sandwich)
e = nn.sem_rep.c(n = 2000)
e
e = nn.sem_rep.c(n = 2000)
nn.sem_rep.c0 = tibble(
rbind(a,b,c,d,e),
col.names = c(
"N",
"Média",
"Viés Absoluto",
"Viés Relativo (%)",
"Cobertura IC (%)"
)
)
#library(boot)
#library(survival)
library(tibble)
nn.sem_rep.c0 = tibble(
rbind(a,b,c,d,e),
col.names = c(
"N",
"Média",
"Viés Absoluto",
"Viés Relativo (%)",
"Cobertura IC (%)"
)
)
View(nn.sem_rep.c0)
?tibble()
nn.sem_rep.c0 = tibble(
"N" = c(a[1], b[1], c[1], d[1], e[1]),
"Média" = c(a[2], b[2], c[2], d[2], e[2]),
"Viés" = c(a[3], b[3], c[3], d[3], e[3]),
"Viés(%)" = c(a[4], b[4], c[4], d[4], e[4]),
"IC(%)" = c(a[5], b[5], c[5], d[5], e[5])
)
View(nn.sem_rep.c0)
save.image("C:/Users/moise/Google Drive/UFBA/PIBIC/Simulação/simulacao_psm/.RData")
nn.sem_rep.c0 = tibble(
"N" = c(a[1], b[1], c[1], d[1], e[1]),
"Média" = c(a[2], b[2], c[2], d[2], e[2]),
"Viés" = c(a[3], b[3], c[3], d[3], e[3]),
"Viés(%)" = c(a[4], b[4], c[4], d[4], e[4]),
"IC(%)" = c(a[5], b[5], c[5], d[5], e[5])
)
e = nn.sem_rep.c(n = 2000)
b = nn.sem_rep.c(n = 400)
c = nn.sem_rep.c(n = 800)
d = nn.sem_rep.c(n = 1500)
nn.sem_rep.c0 = tibble(
"N" = c(a[1], b[1], c[1], d[1]),
"Média" = c(a[2], b[2], c[2], d[2]),
"Viés" = c(a[3], b[3], c[3], d[3]),
"Viés(%)" = c(a[4], b[4], c[4], d[4]),
"IC(%)" = c(a[5], b[5], c[5], d[5])
)
View(nn.sem_rep.c0)
View(nn.sem_rep.c0)
e = nn.sem_rep.c(k = 500, n = 1500)
e = nn.sem_rep.c(k = 350, n = 1500)
rm(e)
View(nn.sem_rep.c0)
#Generatng data similar to Austin (2009) for demonstrating
#treatment effect estimation
gen_X <- function(n) {
X <- matrix(rnorm(9 * n), nrow = n, ncol = 9)
X[,5] <- as.numeric(X[,5] < .5)
X
}
#~20% treated
gen_A <- function(X) {
LP_A <- - 1.2 + log(2)*X[,1] - log(1.5)*X[,2] + log(2)*X[,4] - log(2.4)*X[,5] + log(2)*X[,7] - log(1.5)*X[,8]
P_A <- plogis(LP_A)
rbinom(nrow(X), 1, P_A)
}
# Continuous outcome
gen_Y_C <- function(A, X) {
2*A + 2*X[,1] + 2*X[,2] + 2*X[,3] + 1*X[,4] + 2*X[,5] + 1*X[,6] + rnorm(length(A), 0, 5)
}
#Conditional:
#  MD: 2
#Marginal:
#  MD: 2
# Binary outcome
gen_Y_B <- function(A, X) {
LP_B <- -2 + log(2.4)*A + log(2)*X[,1] + log(2)*X[,2] + log(2)*X[,3] + log(1.5)*X[,4] + log(2.4)*X[,5] + log(1.5)*X[,6]
P_B <- plogis(LP_B)
rbinom(length(A), 1, P_B)
}
#Conditional:
#  OR:   2.4
#  logOR: .875
#Marginal:
#  RD:    .144
#  RR:   1.54
#  logRR: .433
#  OR:   1.92
#  logOR  .655
#------------------------#
#X = gen_X(n)
#A = gen_A(X)
#Y_C = gen_Y_C(A, X)
#Y_B = gen_Y_B(A, X)
#d = data.frame(A, X, Y_C, Y_B)
library(MatchIt)
library(lmtest)
library(sandwich)
nn.sem_rep.c = function(k = 1000, n = 2000) {
estimativas = c()
erros = c()
for (i in 1:k) {
X = gen_X(n)
A = gen_A(X)
Y_C = gen_Y_C(A, X)
Y_B = gen_Y_B(A, X)
d = data.frame(A, X, Y_C, Y_B)
#NN sem reposição
m.out = matchit(A ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9,
data = d)
#m.out
m.data = match.data(m.out)
#head(m.data)
##Para resultados contínuos
###sem ajuste por covariável
fit = lm(Y_C ~ A, data = m.data, weights = m.data$weights)
####Usando cluster-robust standart error
vl = coeftest(fit, vcov. = vcovCL, cluster = ~ subclass)
estimativas[i] = vl[2]
erros[i] = vl[4]
}
valores  = list(estimativas, erros)
return(valores)
}
d = nn.sem_rep.c(n = 1500)
ic = mean(ifelse(2 <= d[[1]] + d[[2]]*1.96 & 2>= d[[1]] - d[[2]]*1.96, 1, 0))
rm(a,b,c,ic,nn.sem_rep.c0)
a = nn.sem_rep.c(n = 150)
ica = mean(ifelse(2 <= a[[1]] + a[[2]]*1.96 & 2>= a[[1]] - a[[2]]*1.96, 1, 0))
b = nn.sem_rep.c(n = 400)
icb = mean(ifelse(2 <= b[[1]] + b[[2]]*1.96 & 2>= b[[1]] - b[[2]]*1.96, 1, 0))
c = nn.sem_rep.c(n = 800)
icc = mean(ifelse(2 <= c[[1]] + c[[2]]*1.96 & 2>= c[[1]] - c[[2]]*1.96, 1, 0))
ic = mean(ifelse(2 <= d[[1]] + d[[2]]*1.96 & 2>= d[[1]] - d[[2]]*1.96, 1, 0))
rm(ic)
icd = mean(ifelse(2 <= d[[1]] + d[[2]]*1.96 & 2>= d[[1]] - d[[2]]*1.96, 1, 0))
mediaa = mean(a[[1]])
mediab = mean(b[[1]])
mediac = mean(c[[1]])
mediad = mean(d[[1]])
vies_mediaa = (mediaa - 2)/mediaa
vies_mediab = (mediab - 2)/mediab
vies_mediac = (mediac - 2)/mediac
vies_mediad = (mediad - 2)/mediad
vies_squarea = sum((2-a[[1]])^2)
/length(a[[1]])
vies_squarea = sum((2-a[[1]])^2)/length(a[[1]])
vies_squareb = sum((2-b[[1]])^2)/length(b[[1]])
vies_squarec = sum((2-c[[1]])^2)/length(c[[1]])
vies_squared = sum((2-d[[1]])^2)//length(d[[1]])
vies_squared = sum((2-d[[1]])^2)/length(d[[1]])
nn.sem_rep.c_table = data.frame(
N = c(150, 400, 800, 1500),
Médias_Estimadas = c(mediaa, mediab, mediac, mediad),
Viés_das_Médias = c(vies_mediaa, vies_mediab, vies_mediac, vies_mediad),
ICs = c(ica, icb, icc, icd),
Viés_Quadrado_Médio = c(vies_squarea, vies_squareb, vies_squarec,
vies_squared)
)
View(nn.sem_rep.c_table)
nn.sem_rep.c_table = data.frame(
N = c(150, 400, 800, 1500),
"Média das Estimativas" = c(mediaa, mediab, mediac, mediad),
"Viés das Médias" = c(vies_mediaa, vies_mediab, vies_mediac, vies_mediad),
"Intervalos de Confinça nominais" = c(ica, icb, icc, icd),
"Viés Quadrado Médio" = c(vies_squarea, vies_squareb, vies_squarec,
vies_squared)
)
nn.sem_rep.c_table = as.tibble(data.frame(
N = c(150, 400, 800, 1500),
"Média das Estimativas" = c(mediaa, mediab, mediac, mediad),
"Viés das Médias" = c(vies_mediaa, vies_mediab, vies_mediac, vies_mediad),
"Intervalos de Confinça nominais" = c(ica, icb, icc, icd),
"Viés Quadrado Médio" = c(vies_squarea, vies_squareb, vies_squarec,
vies_squared)
))
#library(boot)
#library(survival)
library(tibble)
nn.sem_rep.c_table = as.tibble(data.frame(
N = c(150, 400, 800, 1500),
"Média das Estimativas" = c(mediaa, mediab, mediac, mediad),
"Viés das Médias" = c(vies_mediaa, vies_mediab, vies_mediac, vies_mediad),
"Intervalos de Confinça nominais" = c(ica, icb, icc, icd),
"Viés Quadrado Médio" = c(vies_squarea, vies_squareb, vies_squarec,
vies_squared)
))
nn.sem_rep.c_table = as_tibble(data.frame(
N = c(150, 400, 800, 1500),
"Média das Estimativas" = c(mediaa, mediab, mediac, mediad),
"Viés das Médias" = c(vies_mediaa, vies_mediab, vies_mediac, vies_mediad),
"Intervalos de Confinça nominais" = c(ica, icb, icc, icd),
"Viés Quadrado Médio" = c(vies_squarea, vies_squareb, vies_squarec,
vies_squared)
))
View(nn.sem_rep.c_table)
nn.sem_rep.c_table = as_tibble(data.frame(
N = c(150, 400, 800, 1500),
"Média das Estimativas" = c(mediaa, mediab, mediac, mediad),
"Viés das Médias" = c(vies_mediaa, vies_mediab, vies_mediac, vies_mediad),
"Intervalos de Confinça nominais" = c(ica, icb, icc, icd),
"Viés Quadrado Médio" = c(vies_squarea, vies_squareb, vies_squarec,
vies_squared)
))
nn.sem_rep.c_table
View(nn.sem_rep.c_table)
nn.sem_rep.c_table = (data.frame(
N = c(150, 400, 800, 1500),
"Média das Estimativas" = c(mediaa, mediab, mediac, mediad),
"Viés das Médias" = c(vies_mediaa, vies_mediab, vies_mediac, vies_mediad),
"Intervalos de Confinça nominais" = c(ica, icb, icc, icd),
"Viés Quadrado Médio" = c(vies_squarea, vies_squareb, vies_squarec,
vies_squared)
))
View(nn.sem_rep.c_table)
nn.sem_rep.c_table = as_tibble(data.frame(
N = c(150, 400, 800, 1500),
x_barra = c(mediaa, mediab, mediac, mediad),
v_x_barra = c(vies_mediaa, vies_mediab, vies_mediac, vies_mediad),
ics = c(ica, icb, icc, icd),
v_q_medio = c(vies_squarea, vies_squareb, vies_squarec,
vies_squared)
))
View(nn.sem_rep.c_table)
extrai_dados = function(lista, efeito){
ic = mean(ifelse(2 <= lista[[1]] + lista[[2]]*1.96 &
2>= lista[[1]] - lista[[2]]*1.96, 1, 0))
media = mean(lista[[1]])
vies_media = (media-efeito)/media
vies_quadrado = mean((2-lista[[1]])^2)
return(round(c(ic, media, vies_media, vies_quadrado)))
}
extrai_dados = function(lista, efeito){
ic = mean(ifelse(2 <= lista[[1]] + lista[[2]]*1.96 &
2>= lista[[1]] - lista[[2]]*1.96, 1, 0))
media = mean(lista[[1]])
vies_media = (media-efeito)/media
vies_quadrado = mean((2-lista[[1]])^2)
return(round(c(ic, media, vies_media, vies_quadrado)))
}
extrai_dados(a, 2)
extrai_dados = function(lista, efeito){
ic = mean(ifelse(2 <= lista[[1]] + lista[[2]]*1.96 &
2>= lista[[1]] - lista[[2]]*1.96, 1, 0))
media = mean(lista[[1]])
vies_media = (media-efeito)/media
vies_quadrado = mean((2-lista[[1]])^2)
return(round(c(ic, media, vies_media, vies_quadrado),5))
}
extrai_dados(a, 2)
extrai_dados(b, 2)
extrai_dados(c, 2)
extrai_dados(d, 2)
gera_tabela = function(a, b, c, d){
tabela = as_tibble(data.frame(
N = c(150, 400, 800, 1500),
x_barra = c(a[[2]], b[[2]], c[[2]], d[[2]]),
v_x_barra = c(a[[3]], b[[3]], c[[3]], d[[3]]),
ics = c(a[[1]], b[[1]], c[[1]], d[[1]]),
v_q_medio = c(a[[4]], b[[4]], c[[4]], d[[4]])
))
return(tabela)
}
gera_tabela(extrai_dados(a, 2), extrai_dados(b, 2), extrai_dados(c, 2),
extrai_dados(d, 2))
rm(ica,icb,icc,icd,mediaa,mediab,mediac,mediad,vies_mediaa,vies_mediab,vies_mediac, vies_mediad, vies_squarea, vies_squareb, vies_squarec, vies_squared)
extrai_dados = function(lista, efeito){
ic = mean(ifelse(2 <= lista[[1]] + lista[[2]]*1.96 &
2>= lista[[1]] - lista[[2]]*1.96, 1, 0))
media = mean(lista[[1]])
vies_media = (media-efeito)/media
vies_quadrado = mean((2-lista[[1]])^2)
return(round(c(ic, media, vies_media, vies_quadrado),5))
}
gera_tabela = function(a, b, c, d){
tabela = as_tibble(data.frame(
N = c(150, 400, 800, 1500),
x_barra = c(a[[2]], b[[2]], c[[2]], d[[2]]),
v_x_barra = c(a[[3]], b[[3]], c[[3]], d[[3]]),
ics = c(a[[1]], b[[1]], c[[1]], d[[1]]),
v_q_medio = c(a[[4]], b[[4]], c[[4]], d[[4]])
))
return(tabela)
}
gera_tabela(extrai_dados(a, 2), extrai_dados(b, 2), extrai_dados(c, 2),
extrai_dados(d, 2))
rm(nn.sem_rep.c_table)
tabela1 = gera_tabela(extrai_dados(a, 2), extrai_dados(b, 2), extrai_dados(c, 2),
extrai_dados(d, 2))
comment(tabela1) = "Resultados para pareamento NN, sem reposição, na estimativa
do ATT para efeito contínuo."
tabela1
View(tabela1)
comment(tabela1)
comment(tabela1) =
"Resultados para pareamento NN, sem reposição, na estimativa" +
" do ATT para efeito contínuo."
comment(tabela1) =
"Resultados para pareamento NN, sem reposição, na estimativa\n
do ATT para efeito contínuo."
comment(tabela1)
print(comment(tabela1))
cat(comment(tabela1))
comment(tabela1) =
"Resultados para pareamento NN, sem reposição, na estimativa
do ATT para efeito contínuo."
tabela1
cat(comment(tabela1))
View(tabela1)
save.image("C:/Users/moise/Google Drive/UFBA/PIBIC/Simulação/simulacao_psm/.RData")
#Generatng data similar to Austin (2009) for demonstrating
#treatment effect estimation
gen_X <- function(n) {
X <- matrix(rnorm(9 * n), nrow = n, ncol = 9)
X[,5] <- as.numeric(X[,5] < .5)
X
}
#~20% treated
gen_A <- function(X) {
LP_A <- - 1.2 + log(2)*X[,1] - log(1.5)*X[,2] + log(2)*X[,4] - log(2.4)*X[,5] + log(2)*X[,7] - log(1.5)*X[,8]
P_A <- plogis(LP_A)
rbinom(nrow(X), 1, P_A)
}
# Continuous outcome
gen_Y_C <- function(A, X) {
2*A + 2*X[,1] + 2*X[,2] + 2*X[,3] + 1*X[,4] + 2*X[,5] + 1*X[,6] + rnorm(length(A), 0, 5)
}
#Conditional:
#  MD: 2
#Marginal:
#  MD: 2
# Binary outcome
gen_Y_B <- function(A, X) {
LP_B <- -2 + log(2.4)*A + log(2)*X[,1] + log(2)*X[,2] + log(2)*X[,3] + log(1.5)*X[,4] + log(2.4)*X[,5] + log(1.5)*X[,6]
P_B <- plogis(LP_B)
rbinom(length(A), 1, P_B)
}
#Conditional:
#  OR:   2.4
#  logOR: .875
#Marginal:
#  RD:    .144
#  RR:   1.54
#  logRR: .433
#  OR:   1.92
#  logOR  .655
#------------------------#
#X = gen_X(n)
#A = gen_A(X)
#Y_C = gen_Y_C(A, X)
#Y_B = gen_Y_B(A, X)
#d = data.frame(A, X, Y_C, Y_B)
library(MatchIt)
library(lmtest)
library(sandwich)
#library(boot)
#library(survival)
library(tibble)
nn.sem_rep.c.a = function(k = 1000, n = 2000) {
estimativas = c()
erros = c()
for (i in 1:k) {
X = gen_X(n)
A = gen_A(X)
Y_C = gen_Y_C(A, X)
Y_B = gen_Y_B(A, X)
d = data.frame(A, X, Y_C, Y_B)
#NN sem reposição
m.out = matchit(A ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9,
data = d)
#m.out
m.data = match.data(m.out)
#head(m.data)
##Para resultados contínuos
###Com ajuste por co-variável
fit <- lm(Y_C ~ A + X1 + X2 + X3 + X4 + X5 +
X6 + X7 + X8 + X9, data = m.data,
weights = weights)
vl = coeftest(fit, vcov. = vcovCL, cluster = ~subclass)["A",,drop=FALSE]
estimativas[i] = vl[1]
erros[i] = vl[2]
}
valores  = list(estimativas, erros)
return(valores)
}
a1 = nn.sem_rep.c.a(n = 150)
b1 = nn.sem_rep.c.a(n = 400)
save.image("C:/Users/moise/Google Drive/UFBA/PIBIC/Simulação/simulacao_psm/.RData")
c1 = nn.sem_rep.c.a(n = 800)
save.image("C:/Users/moise/Google Drive/UFBA/PIBIC/Simulação/simulacao_psm/.RData")
d1 = nn.sem_rep.c.a(n = 1500)
save.image("C:/Users/moise/Google Drive/UFBA/PIBIC/Simulação/simulacao_psm/.RData")
tabela2 = gera_tabela(extrai_dados(a1, 2), extrai_dados(b1, 2),
extrai_dados(c1, 2), extrai_dados(d1, 2))
comment(tabela2) =
"Resultados para pareamento NN, sem reposição, na estimativa
do ATT para efeito contínuo, com ajuste por co-variável."
View(tabela2)
View(tabela1)
View(tabela2)
View(tabela1)
save.image("C:/Users/moise/Google Drive/UFBA/PIBIC/Simulação/simulacao_psm/.RData")
nn.sem_rep.b.or = function(k = 1000, n = 2000){
estimativas = c()
erros = c()
for (i in 1:k) {
X = gen_X(n)
A = gen_A(X)
Y_C = gen_Y_C(A, X)
Y_B = gen_Y_B(A, X)
d = data.frame(A, X, Y_C, Y_B)
#NN sem reposição
m.out = matchit(A ~ X1 + X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9,
data = d)
m.data = match.data(m.out)
##Para resultados binários
fit = glm(Y_B ~ A, data = m.data, weights = m.data$weights,
family = binomial(link = "logit"))
####Usando cluster-robust standart error
vl = coeftest(fit, vcov. = vcovCL, cluster = ~ subclass)
estimativas[i] = exp(vl[2])
erros[i] = vl[4]
}
valores  = list(estimativas, erros)
return(valores)
}
load("C:/Users/moise/Google Drive/UFBA/PIBIC/Simulação/simulacao_psm/.RData")
library(MatchIt)
library(lmtest)
library(sandwich)
#library(boot)
#library(survival)
library(tibble)
rm(a,b,c,d,a1,b1,c1,d1)
d2 = nn.sem_rep.b.or(n = 1500)
tabela3 = gera_tabela(extrai_dados(a2, 2), extrai_dados(b2, 2),
extrai_dados(c2, 2), extrai_dados(d2, 2))
View(tabela3)
tabela3 = gera_tabela(extrai_dados(a2, 2.4), extrai_dados(b2, 2.4),
extrai_dados(c2, 2.4), extrai_dados(d2, 2.4))
View(tabela3)
tabela3 = gera_tabela(extrai_dados(a2, 2.4), extrai_dados(b2, 2.4),
extrai_dados(c2, 2.4), extrai_dados(d2, 2.4))
View(tabela3)
tabela3 = gera_tabela(extrai_dados(a2, 2), extrai_dados(b2, 2),
extrai_dados(c2, 2), extrai_dados(d2, 2))
View(tabela3)
extrai_dados = function(lista, efeito){
ic = mean(ifelse(efeito <= lista[[1]] + lista[[2]]*1.96 &
efeito>= lista[[1]] - lista[[2]]*1.96, 1, 0))
media = mean(lista[[1]])
vies_media = (media-efeito)/media
vies_quadrado = mean((efeito-lista[[1]])^2)
return(round(c(ic, media, vies_media, vies_quadrado),5))
}
tabela3 = gera_tabela(extrai_dados(a2, 2), extrai_dados(b2, 2),
extrai_dados(c2, 2), extrai_dados(d2, 2))
View(tabela3)
extrai_dados = function(lista, efeito){
ic = mean(ifelse(efeito <= lista[[1]] + lista[[2]]*1.96 &
efeito>= lista[[1]] - lista[[2]]*1.96, 1, 0))
media = mean(lista[[1]])
vies_media = (media-efeito)/media
vies_quadrado = mean((efeito-lista[[1]])^2)
return(round(c(ic, media, vies_media, vies_quadrado),5))
}
tabela3 = gera_tabela(extrai_dados(a2, 2.4), extrai_dados(b2, 2.4),
extrai_dados(c2, 2.4), extrai_dados(d2, 2.4))
View(tabela3)
load("C:/Users/moise/Google Drive/UFBA/PIBIC/Simulação/simulacao_psm/.RData")
library(MatchIt)
library(lmtest)
library(sandwich)
c3 = nn.sem_rep.b.rr(n = 800)
save.image("C:/Users/moise/Google Drive/UFBA/PIBIC/Simulação/simulacao_psm/.RData")
d3 = nn.sem_rep.b.rr(n = 1500)
tabela4 = gera_tabela(extrai_dados.or(a3, 1.54), extrai_dados.or(b3, 1.54),
extrai_dados.or(c3, 1.54), extrai_dados.or(d3, 1.54))
#library(boot)
#library(survival)
library(tibble)
tabela4 = gera_tabela(extrai_dados.or(a3, 1.54), extrai_dados.or(b3, 1.54),
extrai_dados.or(c3, 1.54), extrai_dados.or(d3, 1.54))
View(tabela4)
comment(tabela3) =
"Resultados para pareamento NN, sem reposição, na estimativa
do ATT para efeito binário marginal, sem ajuste por co-variável,
na escala do OR."
comment(tabela4) =
"Resultados para pareamento NN, sem reposição, na estimativa
do ATT para efeito binário marginal, sem ajuste por co-variável,
na escala do RR."
comment(tabela3)
comment(tabela2)
